{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is 1,000,000 rows but a sample size of 10000 is used to save time. However, it is stratified to maintain the same fraud ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/card_transdata.csv')\n",
    "\n",
    "# Get counts of fraud and non-fraud cases\n",
    "fraud_count = df['fraud'].value_counts()\n",
    "min_count = fraud_count.min()\n",
    "\n",
    "# Separate fraud and non-fraud cases\n",
    "fraud_df = df[df['fraud'] == 1].sample(n=min_count, random_state=42)\n",
    "non_fraud_df = df[df['fraud'] == 0].sample(n=min_count, random_state=42)\n",
    "\n",
    "# Combine the balanced datasets\n",
    "df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle the final dataframe\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block normalizes the numeric features using StandardScaler to ensure that the Random Forest algorithm performs effectively. StandardScaler normalizes the data such that the Mean equals 0 and the Standard Deviation equals 1. The binary columns are left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# separate features and labels\n",
    "X = df.drop(columns=['fraud'], axis=1)  \n",
    "y = df['fraud'] \n",
    "\n",
    "# separate binary columns\n",
    "binary_columns = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]\n",
    "\n",
    "# separate continuous columns\n",
    "continuous_columns = [col for col in X.columns if col not in binary_columns]\n",
    "\n",
    "# scale only the continuous columns\n",
    "scaler = StandardScaler()\n",
    "X_scaled_continuous = scaler.fit_transform(df[continuous_columns])\n",
    "\n",
    "# combine binary and scaled continuous data\n",
    "X_scaled = pd.concat(\n",
    "    [pd.DataFrame(X_scaled_continuous, columns=continuous_columns), X[binary_columns].reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check that the classification labels were split properly\n",
    "print(\"\\nValue Counts for Target Labels:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Fraud ratio: {y.mean()}\")\n",
    "\n",
    "# check that the other features were properly scaled\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is run with various combinations of retained variance thresholds and hyperparameters to determine the optimal set of parameters for Random Forest with a PCA approach based primarily on the accuracy, which measures the proportion of correct predictions (both positive and negative) the model makes out of all predictions. The best combination of parameters is maintained for later testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define PCA thresholds and cluster range\n",
    "pca_thresholds = [0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "\n",
    "# define hyperparameters for random forest\n",
    "n_estimators_range = [50, 100, 150]\n",
    "max_depth_range = [None, 10, 20]\n",
    "\n",
    "# to store (pca_threshold, n_estimators, max_depth, mean_accuracy)\n",
    "pca_results = []  \n",
    "\n",
    "original_components = X_scaled.shape[1]\n",
    "\n",
    "for pca_threshold in pca_thresholds:\n",
    "    # apply PCA with the current threshold\n",
    "    pca = PCA(n_components=pca_threshold)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # count retained and removed components\n",
    "    retained_components = pca.n_components_\n",
    "    removed_components = original_components - retained_components\n",
    "\n",
    "    # iterate over hyperparameter combinations\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # train random forest with this combination of parameters\n",
    "            rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "            # use cross-validation to get accuracy\n",
    "            accuracies = cross_val_score(rf, X_pca, y, cv=5, scoring='accuracy')\n",
    "            mean_accuracy = np.mean(accuracies)\n",
    "            pca_results.append((pca_threshold, n_estimators, max_depth, mean_accuracy))\n",
    "            # print metrics\n",
    "            print(\n",
    "                f\"PCA Threshold: {pca_threshold}, n_estimators: {n_estimators}, max_depth: {max_depth}, \"\n",
    "                f\"Mean Accuracy: {mean_accuracy:.4f}, \"\n",
    "                f\"Retained Components: {retained_components}, Removed Components: {removed_components}\"\n",
    "            )\n",
    "\n",
    "# find the best combination of  (pca_threshold, n_estimators, max_depth, mean_accuracy)\n",
    "best_pca_threshold, best_n_estimators_pca, best_max_depth_pca, best_accuracy_pca = max(pca_results, key=lambda x: x[3])\n",
    "print(f\"\\nBest PCA Threshold: {best_pca_threshold}, Best n_estimators: {best_n_estimators_pca}, Best max_depth: {best_max_depth_pca}, Best Mean Accuracy: {best_accuracy_pca:.4f}\")\n",
    "\n",
    "# visualize silhouette scores\n",
    "results_array = np.array(pca_results, dtype=object)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_depth in max_depth_range:\n",
    "        indices = (results_array[:, 1] == n_estimators) & (results_array[:, 2] == max_depth)\n",
    "        thresholds = results_array[indices][:, 0]\n",
    "        accuracies = results_array[indices][:, 3].astype(float)\n",
    "        plt.plot(thresholds, accuracies, marker='o', label=f'n_estimators={n_estimators}, max_depth={max_depth}')\n",
    "\n",
    "plt.title(\"Mean Accuracy for PCA Thresholds and Random Forest Hyperparameters\")\n",
    "plt.xlabel(\"PCA Threshold\")\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of estimators or depth did not seem to have a real effect on the mean accuracy compared to increasing the PCA threshold. The base accuracy is already high so applying the model to the PCA reduced dataset seems very well-suited for this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE is run with various combinations of perplexities and hyperparameters to determine the optimal set of parameters for Random Forest with a t-SNE approach based primarily on the silhouette score and the ARI. The trustworthiness is useful to verify that the local structure of the data is properly reflected after the dimension reduction, which is important for visualization, but the other metrics better measure how well the data is preservered after being reduced. t-SNE seems to prefer a higher amount of n-estimators and a lower perplexity. The higher estimators could be because that in the reduced feature space, each tree in the forest has less information to make a split, and the lower perplexity could  be because t-SNE works better at preserving local structures in data and higher perplexity introduces more noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, trustworthiness\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define t-SNE perplexity values\n",
    "tsne_perplexities = [5, 10, 20, 30, 40]\n",
    "\n",
    "# define random forest hyperparameters\n",
    "n_estimators_range = [50, 100, 150]\n",
    "max_depth_range = [None, 10, 20]\n",
    "\n",
    "# to store (best_tsne_perplexity, best_n_estimators_tsne, best_max_depth_tsne,\n",
    "#  best_accuracy_tsne, best_f1_tsne, best_trustworthiness_tsne)\n",
    "tsne_results = []  \n",
    "\n",
    "# iterate over t-SNE perplexities\n",
    "for perplexity in tsne_perplexities:\n",
    "\n",
    "    # apply t-SNE with the current perplexity\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, learning_rate=200)\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "    # calculate trustworthiness for this t-SNE\n",
    "    trust = trustworthiness(X_scaled, X_tsne, n_neighbors=5)\n",
    "\n",
    "    # iterate over random forest hyperparameter combinations\n",
    "    for n_estimators in n_estimators_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            # train random forest with cross-validation\n",
    "            rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "            scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "            cv_results = cross_validate(rf, X_tsne, y, cv=5, scoring=scoring)\n",
    "            mean_accuracy = np.mean(cv_results['test_accuracy'])\n",
    "            mean_f1 = np.mean(cv_results['test_f1_macro'])\n",
    "            tsne_results.append((perplexity, n_estimators, max_depth, mean_accuracy, mean_f1, trust))\n",
    "            # print details\n",
    "            print(\n",
    "                f\"t-SNE Perplexity: {perplexity}, n_estimators: {n_estimators}, max_depth: {max_depth}, \"\n",
    "                f\"Mean Accuracy: {mean_accuracy:.4f}, Mean F1 Score: {mean_f1:.4f}, Trustworthiness: {trust:.4f}\"\n",
    "            )\n",
    "\n",
    "# find the best combination based on mean F1 score\n",
    "best_tsne_trial = max(tsne_results, key=lambda x: x[4])  # Maximize mean_f1\n",
    "best_tsne_perplexity, best_n_estimators_tsne, best_max_depth_tsne, best_accuracy_tsne, best_f1_tsne, best_trustworthiness_tsne = best_tsne_trial\n",
    "\n",
    "# print the optimal parameters\n",
    "print(f\"\\nBest t-SNE Perplexity: {best_tsne_perplexity}, Best n_estimators: {best_n_estimators_tsne}, Best max_depth: {best_max_depth_tsne}\")\n",
    "print(f\"Best Mean Accuracy: {best_accuracy_tsne:.4f}, Best Mean F1 Score: {best_f1_tsne:.4f}, Best Trustworthiness: {best_trustworthiness_tsne:.4f}\")\n",
    "\n",
    "# visualize mean accuracy and mean f1 Score for t-SNE\n",
    "results_array_tsne = np.array(tsne_results, dtype=object)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plot the mean accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "for i, perplexity in enumerate(tsne_perplexities):\n",
    "    indices = results_array_tsne[:, 0] == perplexity\n",
    "    mean_accuracies = results_array_tsne[indices][:, 3].astype(float)\n",
    "    label = f'Perplexity {perplexity}'\n",
    "    plt.plot(range(len(mean_accuracies)), mean_accuracies, marker='o', label=label)\n",
    "\n",
    "plt.title(\"Mean Accuracy for t-SNE Perplexities\")\n",
    "plt.xlabel(\"Hyperparameter Combination Index\")\n",
    "plt.ylabel(\"Mean Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# plot the mean f1 score\n",
    "plt.subplot(1, 2, 2)\n",
    "for i, perplexity in enumerate(tsne_perplexities):\n",
    "    indices = results_array_tsne[:, 0] == perplexity\n",
    "    mean_f1_scores = results_array_tsne[indices][:, 4].astype(float)\n",
    "    label = f'Perplexity {perplexity}'\n",
    "    plt.plot(range(len(mean_f1_scores)), mean_f1_scores, marker='o', label=label)\n",
    "\n",
    "plt.title(\"Mean F1 Score for t-SNE Perplexities\")\n",
    "plt.xlabel(\"Hyperparameter Combination Index\")\n",
    "plt.ylabel(\"Mean F1 Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block runs cross validation with and without smote on the dataset using either PCA, t-SNE, or no dimension reduction and compares the metrics of the outcomes. Then graphs are generated that show the impact of SMOTE on the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_dimensionality_reduction_and_cv(X, y, method=None, n_splits=5,\n",
    "                                        n_estimators=100, max_depth=None,\n",
    "                                        pca_threshold=None, tsne_perplexity=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - X: Feature matrix\n",
    "    - y: Target labels\n",
    "    - method: 'PCA', 'TSNE', or None for no dimensionality reduction\n",
    "    - n_splits: Number of splits for Stratified K-Fold\n",
    "    - n_estimators: Number of trees in Random Forest\n",
    "    - max_depth: Max depth of the trees in Random Forest\n",
    "    - pca_threshold: Variance threshold for PCA\n",
    "    - tsne_perplexity: Perplexity parameter for t-SNE\n",
    "\n",
    "    Returns:\n",
    "    - Metrics for both SMOTE and non-SMOTE runs\n",
    "    \"\"\"\n",
    "    # run the model with the corresponding dimension reduction technique with the optimal parameters found earlier\n",
    "    if method == \"PCA\":\n",
    "        print(\"Applying PCA...\")\n",
    "        reducer = PCA(n_components=pca_threshold)\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "    elif method == \"TSNE\":\n",
    "        print(\"Applying t-SNE...\")\n",
    "        reducer = TSNE(n_components=2, perplexity=tsne_perplexity, random_state=42, learning_rate=200)\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "    elif method is None:\n",
    "        print(\"No dimensionality reduction...\")\n",
    "        X_reduced = X\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'PCA', 'TSNE', or None\")\n",
    "    \n",
    "    # ensure X_reduced and y are NumPy array\n",
    "    X_reduced = np.array(X_reduced)\n",
    "    y_np = np.array(y)  \n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # calculate SMOTE sizes before folds begin\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_reduced, y)\n",
    "    print(f\"Before SMOTE: X_train size = {X_reduced.shape[0]}, y_train size = {len(y)}\")\n",
    "    print(f\"After SMOTE: X_train_smote size = {X_train_smote.shape[0]}, y_train_smote size = {y_train_smote.shape[0]}\")\n",
    "\n",
    "    fold_results_smote = []\n",
    "    fold_results_no_smote = []\n",
    "\n",
    "    # cross-validation loop\n",
    "    print(f\"\\nRunning Cross-Validation ({'No Dimensionality Reduction' if method is None else method})...\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_reduced, y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        X_train, X_val = X_reduced[train_idx], X_reduced[val_idx]\n",
    "        y_train, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "        # cross-validation WITH SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        rf_smote = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        rf_smote.fit(X_train_smote, y_train_smote)\n",
    "        y_pred_smote = rf_smote.predict(X_val)\n",
    "\n",
    "        # evaluate metrics for SMOTE\n",
    "        accuracy_smote = accuracy_score(y_val, y_pred_smote)\n",
    "        precision_smote = precision_score(y_val, y_pred_smote, pos_label=1, zero_division=0)\n",
    "        recall_smote = recall_score(y_val, y_pred_smote, pos_label=1, zero_division=0)\n",
    "        f1_smote = f1_score(y_val, y_pred_smote, pos_label=1, zero_division=0)\n",
    "        fold_results_smote.append((accuracy_smote, precision_smote, recall_smote, f1_smote))\n",
    "        print(f\"SMOTE - Accuracy: {accuracy_smote:.4f}, Precision: {precision_smote:.4f}, Recall: {recall_smote:.4f}, F1-Score: {f1_smote:.4f}\")\n",
    "\n",
    "        # cross-validation WITHOUT SMOTE\n",
    "        rf_no_smote = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        rf_no_smote.fit(X_train, y_train)\n",
    "        y_pred_no_smote = rf_no_smote.predict(X_val)\n",
    "\n",
    "        # evaluate metrics for non-SMOTE\n",
    "        accuracy_no_smote = accuracy_score(y_val, y_pred_no_smote)\n",
    "        precision_no_smote = precision_score(y_val, y_pred_no_smote, pos_label=1, zero_division=0)\n",
    "        recall_no_smote = recall_score(y_val, y_pred_no_smote, pos_label=1, zero_division=0)\n",
    "        f1_no_smote = f1_score(y_val, y_pred_no_smote, pos_label=1, zero_division=0)\n",
    "        fold_results_no_smote.append((accuracy_no_smote, precision_no_smote, recall_no_smote, f1_no_smote))\n",
    "        \n",
    "        print(f\"No SMOTE - Accuracy: {accuracy_no_smote:.4f}, Precision: {precision_no_smote:.4f}, Recall: {recall_no_smote:.4f}, F1-Score: {f1_no_smote:.4f}\")\n",
    "    \n",
    "    # aggregate metrics\n",
    "    avg_metrics_smote = np.mean(fold_results_smote, axis=0)\n",
    "    avg_metrics_no_smote = np.mean(fold_results_no_smote, axis=0)\n",
    "    print(f\"\\nAverage Metrics Across Folds WITH SMOTE: Accuracy: {avg_metrics_smote[0]:.4f}, Precision: {avg_metrics_smote[1]:.4f}, Recall: {avg_metrics_smote[2]:.4f}, F1-Score: {avg_metrics_smote[3]:.4f}\")\n",
    "    print(f\"Average Metrics Across Folds WITHOUT SMOTE: Accuracy: {avg_metrics_no_smote[0]:.4f}, Precision: {avg_metrics_no_smote[1]:.4f}, Recall: {avg_metrics_no_smote[2]:.4f}, F1-Score: {avg_metrics_no_smote[3]:.4f}\")\n",
    "\n",
    "    return avg_metrics_smote, avg_metrics_no_smote\n",
    "\n",
    "best_n_estimators_no_reduction = 100\n",
    "best_max_depth_no_reduction = None\n",
    "\n",
    "# run for no dimensionality reduction\n",
    "print(\"Running with no dimensionality reduction...\")\n",
    "metrics_no_reduction_smote, metrics_no_reduction_no_smote = run_dimensionality_reduction_and_cv(\n",
    "    X_scaled, y, method=None, n_estimators=best_n_estimators_no_reduction, max_depth=best_max_depth_no_reduction)\n",
    "\n",
    "# run for PCA\n",
    "print(\"\\nRunning PCA...\")\n",
    "metrics_pca_smote, metrics_pca_no_smote = run_dimensionality_reduction_and_cv(\n",
    "    X_scaled, y, method=\"PCA\", n_estimators=best_n_estimators_pca, max_depth=best_max_depth_pca, pca_threshold=best_pca_threshold)\n",
    "\n",
    "# run for t-SNE\n",
    "print(\"\\nRunning t-SNE...\")\n",
    "metrics_tsne_smote, metrics_tsne_no_smote = run_dimensionality_reduction_and_cv(\n",
    "    X_scaled, y, method=\"TSNE\", n_estimators=best_n_estimators_tsne, max_depth=best_max_depth_tsne, tsne_perplexity=best_tsne_perplexity)\n",
    "\n",
    "# collect metrics for plotting\n",
    "methods = [\"No Dimensionality Reduction\", \"PCA\", \"t-SNE\"]\n",
    "metrics_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "# create lists to store metrics\n",
    "smote_metrics_list = [metrics_no_reduction_smote, metrics_pca_smote, metrics_tsne_smote]\n",
    "no_smote_metrics_list = [metrics_no_reduction_no_smote, metrics_pca_no_smote, metrics_tsne_no_smote]\n",
    "\n",
    "# convert lists to NumPy arrays\n",
    "scores_smote = np.array(smote_metrics_list)\n",
    "scores_no_smote = np.array(no_smote_metrics_list)\n",
    "\n",
    "# plot the comparisons with adjacent bars\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35 \n",
    "\n",
    "# loop through all the metrics and create each graph, comparing the scores with and without SMOTE\n",
    "for i, metric_label in enumerate(metrics_labels):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, scores_smote[:, i], width, label=\"With SMOTE\")\n",
    "    plt.bar(x + width/2, scores_no_smote[:, i], width, label=\"Without SMOTE\")\n",
    "    \n",
    "    plt.title(f\"Comparison of {metric_label} Across Dimensionality Reduction Techniques\")\n",
    "    plt.ylabel(metric_label)\n",
    "    plt.xlabel(\"Dimensionality Reduction Technique\")\n",
    "    plt.xticks(x, methods)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The introduction of SMOTE made almost no difference with any of the dimension reduction techniques. Even though the positive case is severely underrepresented, the model still trains on it well. SMOTE  will not be used on the data going forward as I don't think it contributes positively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block evaluates the test set after it has been trained on models using data altered by either PCA, t-SNE, or no dimension reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# function that evaluates a testing function based on a given dimensional reduction method\n",
    "def evaluate_on_test_set(X_train, y_train, X_test, y_test, method=None,\n",
    "                         n_estimators=100, max_depth=None,\n",
    "                         pca_threshold=None, tsne_perplexity=None):\n",
    "    if method == \"PCA\":\n",
    "        reducer = PCA(n_components=best_pca_threshold)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.transform(X_test)\n",
    "    elif method == \"t-SNE\":\n",
    "        reducer = TSNE(n_components=2, perplexity=tsne_perplexity, random_state=42, learning_rate=200)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.fit_transform(X_test) \n",
    "    elif method is None:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dimensionality reduction method\")\n",
    "    \n",
    "    # train random forest with best hyperparameters\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return cm, X_test, y_pred, rf\n",
    "\n",
    "# evaluate test sets and store results\n",
    "methods = [\"No Dimensionality Reduction\", \"PCA\", \"t-SNE\"]\n",
    "test_conf_matrices = {}\n",
    "reduced_test_sets = {}\n",
    "test_predictions = {}\n",
    "\n",
    "# test each method on the test split\n",
    "for method in methods:\n",
    "    if method == \"No Dimensionality Reduction\":\n",
    "        # use the best hyperparameters found earlier to run RF on data with no dimensionality reduction\n",
    "        n_estimators = best_n_estimators_no_reduction\n",
    "        max_depth = best_max_depth_no_reduction\n",
    "        cm, _, y_pred, rf_model = evaluate_on_test_set(\n",
    "            X_train, y_train, X_test, y_test, method=None,\n",
    "            n_estimators=n_estimators, max_depth=max_depth\n",
    "        )\n",
    "        # store the trained model\n",
    "        feature_importance_model = rf_model\n",
    "    elif method == \"PCA\":\n",
    "        # use the best hyperparameters found earlier to run RF on data with PCA dimensionality reduction\n",
    "        cm, X_test_reduced, y_pred, rf_model = evaluate_on_test_set(\n",
    "            X_train, y_train, X_test, y_test, method=\"PCA\",\n",
    "            n_estimators=best_n_estimators_pca, max_depth=best_max_depth_pca,\n",
    "            pca_threshold=best_pca_threshold\n",
    "        )\n",
    "        reduced_test_sets[method] = X_test_reduced\n",
    "    elif method == \"t-SNE\":\n",
    "        # use the best hyperparameters found earlier to run RF on data with t-SNE dimensionality reduction\n",
    "        cm, X_test_reduced, y_pred, rf_model = evaluate_on_test_set(\n",
    "            X_train, y_train, X_test, y_test, method=\"t-SNE\",\n",
    "            n_estimators=best_n_estimators_tsne, max_depth=best_max_depth_tsne,\n",
    "            tsne_perplexity=best_tsne_perplexity\n",
    "        )\n",
    "        reduced_test_sets[method] = X_test_reduced\n",
    "    test_conf_matrices[method] = cm  # store confusion matrices\n",
    "    test_predictions[method] = y_pred\n",
    "\n",
    "# generate heatmaps for the confusion matrices\n",
    "for method, cm in test_conf_matrices.items():\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Non-Fraud\", \"Fraud\"], yticklabels=[\"Non-Fraud\", \"Fraud\"])\n",
    "    plt.title(f\"Confusion Matrix - {method}\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA did not offer much change from no dimensionality reduction. Both of these training methods were very reliable and had high rates of true positives and true negatives. Dimension reduction with t-SNE offered a substantial decrease in performance. t-SNE is more focused on data visualization rather than improving the rate of classification. One problem with t-SNE is that it always reduces to 2 dimensions which could lead to a large loss of relevent information and a less accurate model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block shows the importance of each feature in relation to predicting a fraud case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract non-target feature names \n",
    "feature_names = df.columns.tolist()\n",
    "feature_names.remove('fraud') \n",
    "\n",
    "# used the trained model from the No Dimensionality Reduction trial\n",
    "rf_no_reduction = feature_importance_model\n",
    "\n",
    "# calculate feature importances from the trained model\n",
    "importances = rf_no_reduction.feature_importances_\n",
    "\n",
    "# create a DataFrame for better visualization\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# sort the features by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# plot the feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(\n",
    "    feature_importances_df['Feature'],\n",
    "    feature_importances_df['Importance'],\n",
    "    color='skyblue'\n",
    ")\n",
    "plt.gca().invert_yaxis()  # most important feature at the top\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Random Forest Feature Importances (No Dimensionality Reduction, No SMOTE)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this model, some features are much more important than others. The ratio_to_median_purchase_price, distance_from_home, and online_order seem to be the highest indicators of fraud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
