{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is 1,000,000 rows but a sample size of 10000 is used to save time. However, it is stratified to maintain the same fraud ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/card_transdata.csv')\n",
    "\n",
    "# Get counts of fraud and non-fraud cases\n",
    "fraud_count = df['fraud'].value_counts()\n",
    "min_count = fraud_count.min()\n",
    "\n",
    "# Separate fraud and non-fraud cases\n",
    "fraud_df = df[df['fraud'] == 1].sample(n=min_count, random_state=42)\n",
    "non_fraud_df = df[df['fraud'] == 0].sample(n=min_count, random_state=42)\n",
    "\n",
    "# Combine the balanced datasets\n",
    "df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle the final dataframe\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block normalizes the numeric features using StandardScaler to ensure that the GMM algorithm performs effectively. StandardScaler normalizes the data such that the Mean equals 0 and the Standard Deviation equals 1. The binary columns are left unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# separate features and labels\n",
    "X = df.drop(columns=['fraud'], axis=1) \n",
    "y = df['fraud'] \n",
    "\n",
    "# separate binary columns\n",
    "binary_columns = [col for col in X.columns if set(X[col].unique()) <= {0, 1}]\n",
    "\n",
    "# separate continuous columns\n",
    "continuous_columns = [col for col in X.columns if col not in binary_columns]\n",
    "\n",
    "# scale only the continuous columns\n",
    "scaler = StandardScaler()\n",
    "X_scaled_continuous = scaler.fit_transform(df[continuous_columns])\n",
    "\n",
    "# combine binary and scaled continuous data\n",
    "X_scaled = pd.concat(\n",
    "    [pd.DataFrame(X_scaled_continuous, columns=continuous_columns), X[binary_columns].reset_index(drop=True)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check that the classification labels were split properly\n",
    "print(\"\\nValue Counts for Target Labels:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Fraud ratio: {y.mean()}\")\n",
    "\n",
    "# check that the other features were properly scaled\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is run with various combinations of retained variance thresholds and cluster amount combinations to determine the optimal set of parameters based primarily on the silhouette score which is a value that measures how well connected the clusters are. The best combination of parameters is maintained for later testing. As expected, 2 clusters are usually optimal because the problem is trying to classify between two classes, fraud and non-fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define PCA thresholds and cluster range\n",
    "pca_thresholds = [0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "cluster_range = range(2, 5)\n",
    "\n",
    "# store (pca_threshold, n_clusters, silhouette_score)\n",
    "pca_results = []  \n",
    "\n",
    "original_components = X_scaled.shape[1]\n",
    "\n",
    "for pca_threshold in pca_thresholds:\n",
    "    # apply PCA with the current threshold\n",
    "    pca = PCA(n_components=pca_threshold)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # count retained and removed components\n",
    "    retained_components = pca.n_components_\n",
    "    removed_components = original_components - retained_components\n",
    "\n",
    "    # iterate over the range of clusters\n",
    "    for n_clusters in cluster_range:\n",
    "        # train Gaussian Mixture Model\n",
    "        gmm = GaussianMixture(n_components=n_clusters, n_init=50, covariance_type='tied', random_state=42)\n",
    "        labels = gmm.fit_predict(X_pca)\n",
    "\n",
    "        # calculate the silhouette score\n",
    "        silhouette_avg = silhouette_score(X_pca, labels)\n",
    "        pca_results.append((pca_threshold, n_clusters, silhouette_avg))\n",
    "        # print details\n",
    "        print(\n",
    "            f\"PCA Threshold: {pca_threshold}, Clusters: {n_clusters}, \"\n",
    "            f\"Silhouette Score: {silhouette_avg:.4f}, \"\n",
    "            f\"Retained Components: {retained_components}, Removed Components: {removed_components}\"\n",
    "        )\n",
    "\n",
    "# find the best combination of PCA threshold and number of clusters\n",
    "best_pca_threshold, best_pca_clusters, best_pca_silhouette = max(pca_results, key=lambda x: x[2])\n",
    "print(f\"\\nBest PCA Threshold: {best_pca_threshold}, Best PCA Clusters: {best_pca_clusters}, Best PCA Silhouette Score: {best_pca_silhouette:.4f}\")\n",
    "\n",
    "# visualize silhouette cores\n",
    "results_array = np.array(pca_results)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for threshold in pca_thresholds:\n",
    "    scores = results_array[results_array[:, 0] == threshold][:, 2].astype(float)\n",
    "    plt.plot(cluster_range, scores, marker='o', label=f'PCA {threshold}')\n",
    "\n",
    "plt.title(\"Silhouette Scores for PCA Thresholds and Clusters\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE is run with a various range of perplexities of and cluster amount combinations to determine the optimal set of parameters  based primarily on the silhouette score and the ARI. The trustworthiness is useful to verify that the local structure of the data is properly reflected after the dimension reduction, but the other metrics better measure how well the data is preservered after being reduced. t-SNE doesn't always prefer 2 clusters. I think this is because this method always reduces the data to 2 dimensions (compared to PCA which is variable) which can substantially alter the way the data is preserved, causing the model to recognize more clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE, trustworthiness\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# define t-SNE perplexity values and cluster range\n",
    "tsne_perplexities = [5, 10, 20, 30, 40]\n",
    "cluster_range = range(2, 5)\n",
    "\n",
    "# so store (perplexity, n_clusters, silhouette_score, ARI, trustworthiness)\n",
    "tsne_results = []  \n",
    "\n",
    "# iterate over t-SNE perplexities\n",
    "for perplexity in tsne_perplexities:\n",
    "\n",
    "    # apply t-SNE with the current perplexity\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, learning_rate=200)\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "    # calculate trustworthiness for this t-SNE trial\n",
    "    trust = trustworthiness(X_scaled, X_tsne, n_neighbors=5)\n",
    "\n",
    "    # iterate over the range of clusters\n",
    "    for n_clusters in cluster_range:\n",
    "        # train gmm\n",
    "        gmm = GaussianMixture(n_components=n_clusters, n_init=50, covariance_type='tied', random_state=42)\n",
    "        labels = gmm.fit_predict(X_tsne)\n",
    "\n",
    "        # calculate silhouette score and ARI\n",
    "        silhouette_avg = silhouette_score(X_tsne, labels)\n",
    "        ari_score = adjusted_rand_score(y, labels)\n",
    "\n",
    "        # store results\n",
    "        tsne_results.append((perplexity, n_clusters, silhouette_avg, ari_score, trust))\n",
    "\n",
    "        # print details\n",
    "        print(\n",
    "            f\"t-SNE Perplexity: {perplexity}, Clusters: {n_clusters}, \"\n",
    "            f\"Silhouette Score: {silhouette_avg:.4f}, ARI: {ari_score:.4f}, \"\n",
    "            f\"Trustworthiness: {trust:.4f}\"\n",
    "        )\n",
    "\n",
    "# find the optimal parameters based on ARI and silhouette score, preferring closer to 2 clusters\n",
    "best_tsne_trial = max(\n",
    "    tsne_results,\n",
    "    key=lambda x: (x[3], x[2], -(x[1] == 2))  # prioritize ARI, then silhouette, with slight preference for 2 clusters\n",
    ")\n",
    "best_tsne_perplexity, best_tsne_clusters, best_tsne_silhouette, best_tsne_ari, best_tsne_trustworthiness = best_tsne_trial\n",
    "\n",
    "# print the optimal parameters\n",
    "print(f\"\\nBest t-SNE Perplexity: {best_tsne_perplexity}, Best t-SNE Clusters: {best_tsne_clusters}\")\n",
    "print(f\"Best t-SNE Silhouette Score: {best_tsne_silhouette:.4f}, Best t-SNE ARI: {best_tsne_ari:.4f}\")\n",
    "print(f\"Best t-SNE Trustworthiness: {best_tsne_trustworthiness:.4f}\")\n",
    "\n",
    "# visualize silhouette scores and ARI for t-SNE\n",
    "results_array_tsne = np.array(tsne_results)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# define a color map for each perplexity\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(tsne_perplexities)))\n",
    "\n",
    "# extracts each value from each perplexity of t-SNE to be graphed\n",
    "for i, perplexity in enumerate(tsne_perplexities):\n",
    "    scores = results_array_tsne[results_array_tsne[:, 0] == perplexity][:, 2].astype(float)\n",
    "    ari_scores = results_array_tsne[results_array_tsne[:, 0] == perplexity][:, 3].astype(float)\n",
    "    clusters = results_array_tsne[results_array_tsne[:, 0] == perplexity][:, 1]\n",
    "\n",
    "    # plot silhouette scores with dots\n",
    "    plt.plot(clusters, scores, marker='o', label=f't-SNE {perplexity} Silhouette', color=colors[i])\n",
    "    # plot ARI scores with crosses\n",
    "    plt.plot(clusters, ari_scores, marker='x', label=f't-SNE {perplexity} ARI', color=colors[i])\n",
    "\n",
    "plt.title(\"Metrics for t-SNE Perplexities and Clusters\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Metrics (Silhouette and ARI)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This block runs cross validation with and without smote on the dataset using either PCA, t-SNE, or no dimension reduction and compares the metrics of the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def run_dimensionality_reduction_and_cv(X, y, method=None, n_splits=5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - X: Feature matrix\n",
    "    - y: Target labels\n",
    "    - method: 'PCA', 'TSNE', or None for no dimensionality reduction\n",
    "    - n_splits: Number of splits for Stratified K-Fold\n",
    "\n",
    "    Returns:\n",
    "    - Metrics for both SMOTE and non-SMOTE runs\n",
    "    \"\"\"\n",
    "    # run the model with the corresponding dimension reduction technique with the optimal parameters founde arlier\n",
    "    if method == \"PCA\":\n",
    "        print(\"Applying PCA...\")\n",
    "        reducer = PCA(n_components=best_pca_threshold)\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "        n_clusters = best_pca_clusters\n",
    "    elif method == \"TSNE\":\n",
    "        print(\"Applying t-SNE...\")\n",
    "        reducer = TSNE(n_components=2, perplexity=best_tsne_perplexity, random_state=42, learning_rate=200)\n",
    "        X_reduced = reducer.fit_transform(X)\n",
    "        n_clusters = best_tsne_clusters\n",
    "    elif method is None:\n",
    "        print(\"No dimensionality reduction...\")\n",
    "        X_reduced = X\n",
    "        n_clusters = 2\n",
    "    else:\n",
    "        raise ValueError(\"Method must be 'PCA', 'TSNE', or None\")\n",
    "    \n",
    "    # ensure X_reduced and y are NumPy array for future calculations\n",
    "    X_reduced = np.array(X_reduced)\n",
    "    y_np = np.array(y)  \n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # calculate SMOTE sizes before folds begin\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_reduced, y)\n",
    "    print(f\"Before SMOTE: X_train size = {X_reduced.shape[0]}, y_train size = {len(y)}\")\n",
    "    print(f\"After SMOTE: X_train_smote size = {X_train_smote.shape[0]}, y_train_smote size = {y_train_smote.shape[0]}\")\n",
    "\n",
    "    fold_results_smote = []\n",
    "    fold_results_no_smote = []\n",
    "\n",
    "    # cross-validation loop\n",
    "    print(f\"\\nRunning Cross-Validation ({'No Dimensionality Reduction' if method is None else method})...\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_reduced, y)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        X_train, X_val = X_reduced[train_idx], X_reduced[val_idx]\n",
    "        y_train, y_val = y_np[train_idx], y_np[val_idx]\n",
    "\n",
    "        # cross-validation WITH SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        gmm_smote = GaussianMixture(n_components=n_clusters, n_init=50, covariance_type='tied', random_state=42)\n",
    "        gmm_smote.fit(X_train_smote)\n",
    "        val_clusters_smote = gmm_smote.predict(X_val)\n",
    "\n",
    "        # dynamic label mapping for SMOTE\n",
    "        results_df_smote = pd.DataFrame({'Cluster': val_clusters_smote, 'Actual': y_val})\n",
    "        # uses crosstab to compare the cluster labels and datapoint labals to align them\n",
    "        cluster_label_mapping_smote = pd.crosstab(results_df_smote['Cluster'], results_df_smote['Actual'])\n",
    "        # determines which cluster is the fradulunt one based on which cluster has a true fraud rate closer to the global fraud rate\n",
    "        cluster_to_label_smote = {\n",
    "            cluster: 1.0 if (cluster_label_mapping_smote.loc[cluster, 1.0] / cluster_label_mapping_smote.loc[cluster].sum()) > original_fraud_ratio else 0.0\n",
    "            for cluster in cluster_label_mapping_smote.index\n",
    "        }\n",
    "        # array full of datapoints for each cluster\n",
    "        mapped_val_clusters_smote = [cluster_to_label_smote[cluster] for cluster in val_clusters_smote]\n",
    "\n",
    "        # evaluate metrics for SMOTE\n",
    "        accuracy_smote = accuracy_score(y_val, mapped_val_clusters_smote)\n",
    "        precision_smote = precision_score(y_val, mapped_val_clusters_smote, pos_label=1, zero_division=0)\n",
    "        recall_smote = recall_score(y_val, mapped_val_clusters_smote, pos_label=1, zero_division=0)\n",
    "        f1_smote = f1_score(y_val, mapped_val_clusters_smote, pos_label=1, zero_division=0)\n",
    "        fold_results_smote.append((accuracy_smote, precision_smote, recall_smote, f1_smote))\n",
    "        print(f\"SMOTE - Accuracy: {accuracy_smote:.4f}, Precision: {precision_smote:.4f}, Recall: {recall_smote:.4f}, F1-Score: {f1_smote:.4f}\")\n",
    "\n",
    "        # cross-validation WITHOUT SMOTE\n",
    "        gmm_no_smote = GaussianMixture(n_components=n_clusters, n_init=50, covariance_type='tied', random_state=42)\n",
    "        gmm_no_smote.fit(X_train)\n",
    "        val_clusters_no_smote = gmm_no_smote.predict(X_val)\n",
    "\n",
    "        # dynamic label mapping for non-SMOTE\n",
    "        results_df_no_smote = pd.DataFrame({'Cluster': val_clusters_no_smote, 'Actual': y_val})\n",
    "        # uses crosstab to compare the cluster labels and datapoint labals to align them\n",
    "        cluster_label_mapping_no_smote = pd.crosstab(results_df_no_smote['Cluster'], results_df_no_smote['Actual'])\n",
    "        # determines which cluster is the fradulunt one based on which cluster has a true fraud rate closer to the global fraud rate\n",
    "        cluster_to_label_no_smote = {\n",
    "            cluster: 1.0 if (cluster_label_mapping_no_smote.loc[cluster, 1.0] / cluster_label_mapping_no_smote.loc[cluster].sum()) > original_fraud_ratio else 0.0\n",
    "            for cluster in cluster_label_mapping_no_smote.index\n",
    "        }\n",
    "        # array full of datapoints for each cluster\n",
    "        mapped_val_clusters_no_smote = [cluster_to_label_no_smote[cluster] for cluster in val_clusters_no_smote]\n",
    "\n",
    "        # evaluate metrics for non-SMOTE\n",
    "        accuracy_no_smote = accuracy_score(y_val, mapped_val_clusters_no_smote)\n",
    "        precision_no_smote = precision_score(y_val, mapped_val_clusters_no_smote, pos_label=1, zero_division=0)\n",
    "        recall_no_smote = recall_score(y_val, mapped_val_clusters_no_smote, pos_label=1, zero_division=0)\n",
    "        f1_no_smote = f1_score(y_val, mapped_val_clusters_no_smote, pos_label=1, zero_division=0)\n",
    "        fold_results_no_smote.append((accuracy_no_smote, precision_no_smote, recall_no_smote, f1_no_smote))\n",
    "        print(f\"No SMOTE - Accuracy: {accuracy_no_smote:.4f}, Precision: {precision_no_smote:.4f}, Recall: {recall_no_smote:.4f}, F1-Score: {f1_no_smote:.4f}\")\n",
    "\n",
    "    # aggregate metrics\n",
    "    avg_metrics_smote = np.mean(fold_results_smote, axis=0)\n",
    "    avg_metrics_no_smote = np.mean(fold_results_no_smote, axis=0)\n",
    "    print(f\"\\nAverage Metrics Across Folds WITH SMOTE: Accuracy: {avg_metrics_smote[0]:.4f}, Precision: {avg_metrics_smote[1]:.4f}, Recall: {avg_metrics_smote[2]:.4f}, F1-Score: {avg_metrics_smote[3]:.4f}\")\n",
    "    print(f\"Average Metrics Across Folds WITHOUT SMOTE: Accuracy: {avg_metrics_no_smote[0]:.4f}, Precision: {avg_metrics_no_smote[1]:.4f}, Recall: {avg_metrics_no_smote[2]:.4f}, F1-Score: {avg_metrics_no_smote[3]:.4f}\")\n",
    "\n",
    "    return avg_metrics_smote, avg_metrics_no_smote\n",
    "\n",
    "# run for no dimensionality reduction\n",
    "print(\"Running with no dimensionality reduction...\")\n",
    "metrics_no_reduction_smote, metrics_no_reduction_no_smote = run_dimensionality_reduction_and_cv(X_scaled, y, method=None)\n",
    "\n",
    "# run for PCA\n",
    "print(\"\\nRunning PCA...\")\n",
    "metrics_pca_smote, metrics_pca_no_smote = run_dimensionality_reduction_and_cv(X_scaled, y, method=\"PCA\")\n",
    "\n",
    "# run for t-SNE\n",
    "print(\"\\nRunning t-SNE...\")\n",
    "metrics_tsne_smote, metrics_tsne_no_smote = run_dimensionality_reduction_and_cv(X_scaled, y, method=\"TSNE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE consistently improves all metrics with all reduction techniques, likely because of the low ratio of fraud to non-fruad. t-SNE performed better on average in all metrics compared to PCA and no dimension reduction. The upcoming block graphs the impacts of SMOTE on each technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# metrics from the output\n",
    "metrics = {\n",
    "    \"No Dimensionality Reduction\": {\n",
    "        \"SMOTE\": metrics_no_reduction_smote,\n",
    "        \"No SMOTE\": metrics_no_reduction_no_smote\n",
    "    },\n",
    "    \"PCA\": {\n",
    "        \"SMOTE\": metrics_pca_smote,\n",
    "        \"No SMOTE\": metrics_pca_no_smote\n",
    "    },\n",
    "    \"t-SNE\": {\n",
    "        \"SMOTE\": metrics_tsne_smote,\n",
    "        \"No SMOTE\": metrics_tsne_no_smote\n",
    "    }\n",
    "}\n",
    "\n",
    "# plot the comparison with adjacent bars\n",
    "methods = list(metrics.keys())\n",
    "scores_smote = np.array([metrics[method][\"SMOTE\"] for method in methods])\n",
    "scores_no_smote = np.array([metrics[method][\"No SMOTE\"] for method in methods])\n",
    "metrics_labels = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35 \n",
    "\n",
    "for i, metric_label in enumerate(metrics_labels):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, scores_smote[:, i], width, label=\"With SMOTE\")\n",
    "    plt.bar(x + width/2, scores_no_smote[:, i], width, label=\"Without SMOTE\")\n",
    "    \n",
    "    plt.title(f\"Comparison of {metric_label} Across Dimensionality Reduction Techniques\")\n",
    "    plt.ylabel(metric_label)\n",
    "    plt.xlabel(\"Dimensionality Reduction Technique\")\n",
    "    plt.xticks(x, methods)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The introduction of SMOTE improves all metrics except Recall in all 3 dimensionality reductions. The addition of SMOTE dispropoirtionately increases the amount of fraud cases in the sample, causing the model to be more likely to predict fraud in a non-fraud case, decreasing the amount of frauds detected correctly as the model becomes more prone to false positives. The increase in fraud cases helps with the relatively low amount of fraud cases in the sample, helping the model correctly identify fraud cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block evaluates the test set after it has been trained on models using data altered by either PCA, t-SNE, or no dimension reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# evaluate each testing function based on a different dimensional reduction using the optimal parameters\n",
    "def evaluate_on_test_set(X_train, y_train, X_test, y_test, method=None):\n",
    "    if method == \"PCA\":\n",
    "        reducer = PCA(n_components=best_pca_threshold)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.transform(X_test)\n",
    "        n_clusters = best_pca_clusters\n",
    "    elif method == \"t-SNE\":\n",
    "        reducer = TSNE(n_components=2, perplexity=best_tsne_perplexity, random_state=42, learning_rate=200)\n",
    "        X_train = reducer.fit_transform(X_train)\n",
    "        X_test = reducer.fit_transform(X_test) \n",
    "        n_clusters = best_tsne_clusters\n",
    "    elif method is None:\n",
    "        n_clusters = 2\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dimensionality reduction method\")\n",
    "\n",
    "    # the dataset is upsampled with SMOTE due to the positive affects on metrics\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # the model is fit and predicted with the smote altered dataset and the optimal parameters\n",
    "    gmm = GaussianMixture(n_components=n_clusters, n_init=50, covariance_type='tied', random_state=42)\n",
    "    gmm.fit(X_train_smote)\n",
    "    test_clusters = gmm.predict(X_test)\n",
    "\n",
    "    # the same process of assigning each datapoint a cluster, and each cluster a label\n",
    "    results_df = pd.DataFrame({'Cluster': test_clusters, 'Actual': y_test})\n",
    "    cluster_label_mapping = pd.crosstab(results_df['Cluster'], results_df['Actual'])\n",
    "    cluster_to_label = {\n",
    "        cluster: 1.0 if (cluster_label_mapping.loc[cluster, 1.0] / cluster_label_mapping.loc[cluster].sum()) > original_fraud_ratio else 0.0\n",
    "        for cluster in cluster_label_mapping.index\n",
    "    }\n",
    "    mapped_test_clusters = [cluster_to_label[cluster] for cluster in test_clusters]\n",
    "\n",
    "    # create a confusion matrix based on the test results\n",
    "    cm = confusion_matrix(y_test, mapped_test_clusters)\n",
    "\n",
    "    return cm, X_test, test_clusters\n",
    "\n",
    "# evaluate test sets and store results\n",
    "methods = [\"No Dimensionality Reduction\", \"PCA\", \"t-SNE\"]\n",
    "test_conf_matrices = {}\n",
    "reduced_test_sets = {}\n",
    "test_clusters_results = {}\n",
    "\n",
    "# creates a confusion matrix for each method of dimensionality reduction\n",
    "for method in methods:\n",
    "    if method == \"No Dimensionality Reduction\":\n",
    "        cm, _, _ = evaluate_on_test_set(X_train, y_train, X_test, y_test, method=None)\n",
    "    else:\n",
    "        cm, X_test_reduced, test_clusters = evaluate_on_test_set(X_train, y_train, X_test, y_test, method)\n",
    "        reduced_test_sets[method] = X_test_reduced\n",
    "        test_clusters_results[method] = test_clusters\n",
    "\n",
    "    test_conf_matrices[method] = cm  # store confusion matrices\n",
    "\n",
    "# generate heatmaps for the confusion matrices\n",
    "for method, cm in test_conf_matrices.items():\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Non-Fraud\", \"Fraud\"], yticklabels=[\"Non-Fraud\", \"Fraud\"])\n",
    "    plt.title(f\"Confusion Matrix - {method}\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA did not offer much change from no dimensionality reduction. Both of these training methods heavily favored non fraud so the likely reason for their high accuracy is because they never guess fraud, leading to a lot of false positives. Dimension reduction with t-SNE offered a substantial improvement, although still not good enough to use reliably. The model trained on data reduced by t-SNE correctly identified 223 fraud cases, a dramatic increase up from 4. However, this version of the model had a significantly higher false positive rate. Since the overall rate of fraud is so low, this could be suboptimal as it could misflag many more transactions that necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block graphs the clusters in unique colors, with a seperate hollow red triange symbol that highlights the fraud causes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# function to plot clusters dynamically for any number of clusters\n",
    "def plot_clusters(X_test_transformed, y_test, clusters, method_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # define a distinct color palette for clusters (excluding red)\n",
    "    cluster_colors = ['blue', 'green', 'orange', 'purple', 'yellow', 'cyan', 'magenta', 'brown', 'pink', 'gray']\n",
    "    unique_clusters = np.unique(clusters)\n",
    "\n",
    "    if len(unique_clusters) > len(cluster_colors):\n",
    "        raise ValueError(\"Too many clusters for the predefined color palette. Add more colors if needed.\")\n",
    "\n",
    "    # plot each cluster with a distinct color\n",
    "    for i, cluster in enumerate(unique_clusters):\n",
    "        cluster_indices = (clusters == cluster)\n",
    "        plt.scatter(\n",
    "            X_test_transformed[cluster_indices, 0],\n",
    "            X_test_transformed[cluster_indices, 1],\n",
    "            c=cluster_colors[i],\n",
    "            marker='s',\n",
    "            label=f\"Cluster {cluster}\",\n",
    "            alpha=0.7\n",
    "        )\n",
    "\n",
    "    # overlay true fraud cases (y_test == 1) as hollow red triangles\n",
    "    true_fraud_indices = (y_test == 1).values\n",
    "    plt.scatter(\n",
    "        X_test_transformed[true_fraud_indices, 0],\n",
    "        X_test_transformed[true_fraud_indices, 1],\n",
    "        edgecolor='red',\n",
    "        facecolor=\"none\",\n",
    "        marker='^',\n",
    "        linewidths=0.8,\n",
    "        s=80,\n",
    "        label=\"True Fraud (Hollow Triangle)\"\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Cluster Visualization - {method_name}\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend(title=\"Legend\", loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# graph clusters for PCA and t-SNE\n",
    "for method in [\"PCA\", \"t-SNE\"]:\n",
    "    if method in reduced_test_sets:\n",
    "        plot_clusters(\n",
    "            reduced_test_sets[method],\n",
    "            y_test,\n",
    "            test_clusters_results[method],\n",
    "            method_name=method\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters are visualized on each of the graphs, one with a PCA reduction and the other with t-SNE. In each graph, the fraudulunt data points (the red hollow triangles) don't seem to relate with any of the other clusters. This fact, combined with the lack of reliable testing results after many forms of preprocessing leads me to believe that the GMM model is not well suited for this classification problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
